import os
import time
import wave
import json
import subprocess
import psutil

from vosk import Model, KaldiRecognizer
from faster_whisper import WhisperModel
from jiwer import wer, Compose, RemovePunctuation, ToLowerCase, RemoveWhiteSpace

# === à¹€à¸•à¸£à¸µà¸¢à¸¡à¸§à¸±à¸”à¸—à¸£à¸±à¸à¸¢à¸²à¸à¸£ ===
process = psutil.Process(os.getpid())

def measure_resource(fn):
    start_time = time.time()
    cpu_start = process.cpu_percent(interval=None)
    mem_start = process.memory_info().rss / 1024 / 1024  # MB

    result = fn()

    cpu_end = process.cpu_percent(interval=None)
    mem_end = process.memory_info().rss / 1024 / 1024  # MB
    end_time = time.time()

    latency = end_time - start_time
    cpu_used = cpu_end
    mem_used = mem_end - mem_start
    return result, latency, cpu_used, mem_used

# === à¹€à¸¥à¸·à¸­à¸à¹„à¸Ÿà¸¥à¹Œà¹€à¸ªà¸µà¸¢à¸‡ ===
wav_files = [f for f in os.listdir(".") if f.endswith(".wav")]
if not wav_files:
    print("âŒ à¹„à¸¡à¹ˆà¸à¸šà¹„à¸Ÿà¸¥à¹Œ .wav")
    exit()

print("ğŸ“‚ à¹€à¸¥à¸·à¸­à¸à¹„à¸Ÿà¸¥à¹Œà¹€à¸ªà¸µà¸¢à¸‡:")
for i, f in enumerate(wav_files):
    print(f"[{i}] {f}")

idx = int(input("à¸à¸£à¸¸à¸“à¸²à¹€à¸¥à¸·à¸­à¸à¸«à¸¡à¸²à¸¢à¹€à¸¥à¸‚à¹„à¸Ÿà¸¥à¹Œ: "))
orig_wav = wav_files[idx]
txt_file = orig_wav.replace(".wav", ".txt")
converted_wav = "converted_temp.wav"

if not os.path.exists(txt_file):
    print(f"âŒ à¹„à¸¡à¹ˆà¸à¸šà¹„à¸Ÿà¸¥à¹Œ {txt_file} à¸ªà¸³à¸«à¸£à¸±à¸š ground truth")
    exit()

# === à¹à¸›à¸¥à¸‡à¹„à¸Ÿà¸¥à¹Œ .wav à¹€à¸›à¹‡à¸™ PCM ===
print(f"ğŸ”„ à¹à¸›à¸¥à¸‡à¹„à¸Ÿà¸¥à¹Œ {orig_wav} â†’ PCM format...")
subprocess.run([
    "ffmpeg", "-y", "-i", orig_wav,
    "-acodec", "pcm_s16le", "-ar", "16000", "-ac", "1",
    converted_wav
], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

# === à¹‚à¸«à¸¥à¸” ground truth ===
with open(txt_file, "r", encoding="utf-8") as f:
    ground_truth = f.read().strip().lower()

# === à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™ normalize à¸ªà¸³à¸«à¸£à¸±à¸š WER ===
transform = Compose([
    RemovePunctuation(),
    ToLowerCase(),
    RemoveWhiteSpace(replace_by_space=True),
])

# === à¸£à¸±à¸™ Vosk ===
def run_vosk():
    model = Model("/models/vosk/model")
    wf = wave.open(converted_wav, "rb")
    audio_data = wf.readframes(wf.getnframes())
    rec = KaldiRecognizer(model, wf.getframerate())
    rec.AcceptWaveform(audio_data)
    result = rec.Result()
    return json.loads(result)["text"]

print("\nğŸ§  Running Vosk...")
vosk_text, vosk_time, vosk_cpu, vosk_mem = measure_resource(run_vosk)

# === à¸£à¸±à¸™ Whisper ===
def run_whisper():
    model = WhisperModel("tiny.en", download_root="/models/whisper")
    segments, _ = model.transcribe(converted_wav)
    return " ".join([seg.text for seg in segments])

print("\nğŸ§  Running Whisper...")
whisper_text, whisper_time, whisper_cpu, whisper_mem = measure_resource(run_whisper)

# === à¹à¸ªà¸”à¸‡à¸œà¸¥ ===
print("\nğŸ§¾ Ground Truth:", ground_truth)

print("\nğŸ™ï¸ Whisper Output:", whisper_text.strip().lower())
print("ğŸ• Latency: %.2f sec | âš™ï¸ CPU: %.2f%% | ğŸ“¦ RAM: %.2f MB" % (whisper_time, whisper_cpu, whisper_mem))
print("ğŸ“‰ WER: %.2f%%" % (wer(transform(ground_truth), transform(whisper_text)) * 100))

print("\nğŸ™ï¸ Vosk Output:", vosk_text.strip().lower())
print("ğŸ• Latency: %.2f sec | âš™ï¸ CPU: %.2f%% | ğŸ“¦ RAM: %.2f MB" % (vosk_time, vosk_cpu, vosk_mem))
print("ğŸ“‰ WER: %.2f%%" % (wer(transform(ground_truth), transform(vosk_text)) * 100))

# === à¸¥à¸šà¹„à¸Ÿà¸¥à¹Œà¹à¸›à¸¥à¸‡à¸Šà¸±à¹ˆà¸§à¸„à¸£à¸²à¸§
os.remove(converted_wav)
